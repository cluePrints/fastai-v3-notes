{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai3 part2: 03_minibatch_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cluePrints/fastai-v3-notes/blob/master/fastai3_part2_03_minibatch_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WZ8csvZQjCY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import datasets\n",
        "import torch\n",
        "import gzip, pickle\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'\n",
        "\n",
        "def get_data():\n",
        "  path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "  with gzip.open(path) as f:\n",
        "    ((train_X, train_Y), (valid_X, valid_Y), (test_X, test_Y)) = pickle.load(f, encoding='latin')\n",
        "\n",
        "  train_X = torch.tensor(train_X)\n",
        "  train_Y = torch.tensor(train_Y)\n",
        "  valid_X = torch.tensor(valid_X)\n",
        "  valid_Y = torch.tensor(valid_Y)\n",
        "  return train_X, train_Y, valid_X, valid_Y\n",
        "\n",
        "import operator\n",
        "\n",
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')\n",
        "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "def test_near(a,b): test(a,b,near)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtPOjSCgi8pU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_X, train_Y, valid_X, valid_Y = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3Fokia-kBb7",
        "colab_type": "code",
        "outputId": "12df1b0a-3188-43a4-fd25-4d9722d40c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_X.shape, train_Y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 784]), torch.Size([50000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "PSj9qbHZkPl_",
        "colab_type": "code",
        "outputId": "6c1d9386-770a-4c4b-f419-548c3c4cb0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "n_classes = len(train_Y.unique())\n",
        "n_classes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "t-6VgY61kbhT",
        "colab_type": "code",
        "outputId": "6c2202ab-415a-4ab5-bbbd-a1e0105008e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "n_inputs = train_X.shape[-1]\n",
        "n_inputs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "XG3drd5ajN5m",
        "colab_type": "code",
        "outputId": "eaa3ae0a-13cd-4675-d524-99f16d8eda96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, n_hidden, n_out):\n",
        "    super(Model, self).__init__()\n",
        "    self.lin1 = nn.Linear(n_in, n_hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(n_hidden, n_out)\n",
        "    self.layers = [self.lin1, self.relu, self.lin2]\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    result = x\n",
        "    for layer in self.layers:\n",
        "      result = layer(result)\n",
        "    \n",
        "    return result\n",
        "\n",
        "n_hidden = 100\n",
        "model = Model(n_inputs, n_hidden, n_classes)\n",
        "preds = model(train_X)\n",
        "preds.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "oHnk7ujPli1S",
        "colab_type": "code",
        "outputId": "1491b75d-b329-4ed0-c881-0707df860b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "preds[:,train_Y].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "FrGk9zjBljnY",
        "colab_type": "code",
        "outputId": "093286e5-af90-422a-af32-c7ce2d514b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "preds[train_Y].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "3Q2MRbihlrvr",
        "colab_type": "code",
        "outputId": "1594063c-b0b3-48de-e12e-213bd9245a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "preds[0,:], train_Y[0], preds[train_Y][0], preds[0,train_Y[0]]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0603, -0.0133,  0.1480, -0.0486,  0.1027,  0.0019, -0.0256,  0.0478,\n",
              "         -0.0038,  0.0125], grad_fn=<SliceBackward>),\n",
              " tensor(5),\n",
              " tensor([-0.0559, -0.1007,  0.1279, -0.0858,  0.1533,  0.0603,  0.0099,  0.1177,\n",
              "         -0.0433,  0.1035], grad_fn=<SelectBackward>),\n",
              " tensor(0.0019, grad_fn=<SelectBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Hw2BlYm7mPRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_softmax(row):\n",
        "  return row.exp()/row.exp().sum()\n",
        "\n",
        "row = preds[train_Y][0]\n",
        "test_near(my_softmax(row), row.softmax(dim=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F2o20Z21nqSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_logsfotmax(row):\n",
        "  # log(row.exp()/row.exp().sum()) = \n",
        "  # row.exp().log() - row.exp().sum().log()\n",
        "  # row - row.exp().sum().log()\n",
        "  # row - ((row-max).exp().sum() + max.exp()).log()       <-- Note to self: without this guy the below results differs like 10%\n",
        "  return row - row.exp().sum(dim=-1, keepdim=True).log()\n",
        "\n",
        "test_near(my_logsfotmax(row), row.log_softmax(dim=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RhDObWREpf0p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_logsfotmax(matrix):\n",
        "  # log(row.exp()/row.exp().sum()) = \n",
        "  # row.exp().log() - row.exp().sum().log()\n",
        "  # row - row.exp().sum().log()\n",
        "  # row - ((row-max).exp().sum() + max.exp()).log()\n",
        "  rowsmax = matrix.max(dim=-1)\n",
        "  rowsmax_vals = rowsmax[0]\n",
        "  rowsmax_vals = rowsmax_vals[:,None]\n",
        "  logsumexp = rowsmax_vals + (matrix-rowsmax_vals).exp().sum(dim=-1, keepdim=True).log()\n",
        "  return matrix - logsumexp\n",
        "\n",
        "test_near(my_logsfotmax(preds), preds.log_softmax(dim=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v92bNyuKsFLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_nll(lsmax, y):\n",
        "  # Note to self: had to put range here, colon was a bad idea because it means broadcasting\n",
        "  return -lsmax[range(len(y)), y].mean()\n",
        "\n",
        "test_near(my_nll(my_logsfotmax(preds), train_Y),\n",
        "          F.nll_loss(preds.log_softmax(dim=-1), train_Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vQIw06X5Ax1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_near(my_nll(my_logsfotmax(preds), train_Y),\n",
        "          F.cross_entropy(preds, train_Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Ak9_L7L4LYp",
        "colab_type": "code",
        "outputId": "6759959a-4b47-4d04-aa97-0e3c1c8e3a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(n_inputs, n_hidden, n_classes)\n",
        "\n",
        "batch_size = 4096\n",
        "# Note to self: be careful not to have last batch of size 0\n",
        "n_batches = (len(train_X) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "lr = 0.8\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches}\")\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x = train_X[start_idx:end_idx]\n",
        "    batch_y = train_Y[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    print(f\"  {loss.item()}\")\n",
        "    with torch.no_grad():\n",
        "      model.lin1.weight -= model.lin1.weight.grad * lr\n",
        "      model.lin1.bias   -= model.lin1.bias.grad * lr\n",
        "      model.lin2.weight -= model.lin2.weight.grad * lr\n",
        "      model.lin2.bias   -= model.lin2.bias.grad * lr\n",
        "      model.lin1.weight.grad.zero_()\n",
        "      model.lin2.weight.grad.zero_()\n",
        "      model.lin1.bias.grad.zero_()\n",
        "      model.lin2.bias.grad.zero_()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13\n",
            "  2.2996182441711426\n",
            "Training batch 2 of 13\n",
            "  2.17569637298584\n",
            "Training batch 3 of 13\n",
            "  2.011753559112549\n",
            "Training batch 4 of 13\n",
            "  1.8213253021240234\n",
            "Training batch 5 of 13\n",
            "  1.583311915397644\n",
            "Training batch 6 of 13\n",
            "  1.338706612586975\n",
            "Training batch 7 of 13\n",
            "  1.2961739301681519\n",
            "Training batch 8 of 13\n",
            "  1.875916600227356\n",
            "Training batch 9 of 13\n",
            "  1.8761314153671265\n",
            "Training batch 10 of 13\n",
            "  1.5657845735549927\n",
            "Training batch 11 of 13\n",
            "  1.4264986515045166\n",
            "Training batch 12 of 13\n",
            "  1.0599159002304077\n",
            "Training batch 13 of 13\n",
            "  1.070555329322815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MCoTC5V783KA",
        "colab_type": "code",
        "outputId": "18e4f83d-69df-47f4-eb4e-c9d96613125c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(n_inputs, n_hidden, n_classes)\n",
        "\n",
        "batch_size = 4096\n",
        "n_batches = (len(train_X) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "lr = 0.8\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches}\")\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x = train_X[start_idx:end_idx]\n",
        "    batch_y = train_Y[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    print(f\"  {loss.item()}\")\n",
        "    with torch.no_grad():\n",
        "      for layer in model.layers:\n",
        "        if not isinstance(layer, nn.Linear):\n",
        "          continue\n",
        "        \n",
        "      layer.weight -= layer.weight.grad * lr\n",
        "      layer.bias   -= layer.bias.grad * lr\n",
        "\n",
        "      layer.bias.grad.zero_()\n",
        "      layer.bias.grad.zero_()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13\n",
            "  2.3082618713378906\n",
            "Training batch 2 of 13\n",
            "  2.2934176921844482\n",
            "Training batch 3 of 13\n",
            "  2.266172409057617\n",
            "Training batch 4 of 13\n",
            "  2.22622013092041\n",
            "Training batch 5 of 13\n",
            "  2.1741018295288086\n",
            "Training batch 6 of 13\n",
            "  2.1078577041625977\n",
            "Training batch 7 of 13\n",
            "  2.036240816116333\n",
            "Training batch 8 of 13\n",
            "  1.9903026819229126\n",
            "Training batch 9 of 13\n",
            "  1.884812593460083\n",
            "Training batch 10 of 13\n",
            "  1.797560691833496\n",
            "Training batch 11 of 13\n",
            "  1.7426574230194092\n",
            "Training batch 12 of 13\n",
            "  1.6193019151687622\n",
            "Training batch 13 of 13\n",
            "  1.601128339767456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ArA_WTH8RxeX",
        "colab_type": "code",
        "outputId": "0c7643bc-93f4-47b3-fc31-132d7324bfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, n_hidden, n_out):\n",
        "    super(Model, self).__init__()\n",
        "    self.lin1 = nn.Linear(n_in, n_hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(n_hidden, n_out)\n",
        "    self.layers = [self.lin1, self.relu, self.lin2]\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    result = x\n",
        "    for layer in self.layers:\n",
        "      result = layer(result)\n",
        "    \n",
        "    return result\n",
        "  \n",
        "  def params(self):\n",
        "    for layer in self.layers:\n",
        "      for param in layer.parameters():\n",
        "        yield param;\n",
        "\n",
        "model = Model(n_inputs, n_hidden, n_classes)\n",
        "\n",
        "batch_size = 4096\n",
        "n_batches = (len(train_X) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "lr = 0.8\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches}\")\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x = train_X[start_idx:end_idx]\n",
        "    batch_y = train_Y[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    print(f\"  {loss.item()}\")\n",
        "    with torch.no_grad():\n",
        "      for param in model.params():\n",
        "        param.sub_(param.grad * lr)\n",
        "      model.zero_grad()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13\n",
            "  2.3152432441711426\n",
            "Training batch 2 of 13\n",
            "  2.1860506534576416\n",
            "Training batch 3 of 13\n",
            "  2.0262773036956787\n",
            "Training batch 4 of 13\n",
            "  1.852264404296875\n",
            "Training batch 5 of 13\n",
            "  1.6146730184555054\n",
            "Training batch 6 of 13\n",
            "  1.3679393529891968\n",
            "Training batch 7 of 13\n",
            "  1.3271557092666626\n",
            "Training batch 8 of 13\n",
            "  2.006197214126587\n",
            "Training batch 9 of 13\n",
            "  1.8821645975112915\n",
            "Training batch 10 of 13\n",
            "  1.7415269613265991\n",
            "Training batch 11 of 13\n",
            "  1.4774370193481445\n",
            "Training batch 12 of 13\n",
            "  1.19278085231781\n",
            "Training batch 13 of 13\n",
            "  1.0323290824890137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pAVz_V5IR5Bv",
        "colab_type": "code",
        "outputId": "b787f863-36f0-4892-c94e-02c463fe3851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "# registration\n",
        "class Model():\n",
        "  def __init__(self, n_in, n_hidden, n_out):\n",
        "    self._layers = []\n",
        "    self._layers_by_name = {}\n",
        "    self.lin1 = nn.Linear(n_in, n_hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lin2 = nn.Linear(n_hidden, n_out)\n",
        "    \n",
        "  def __setattr__(self, name, val):\n",
        "    super().__setattr__(name, val)\n",
        "    if (name.startswith(\"_\")):\n",
        "      return\n",
        "\n",
        "    self._layers.append(val)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    result = x\n",
        "    for layer in self._layers:\n",
        "      result = layer(result)\n",
        "    \n",
        "    return result\n",
        "  \n",
        "  def params(self):\n",
        "    for layer in self._layers:\n",
        "      for param in layer.parameters():\n",
        "        yield param;\n",
        "\n",
        "model = Model(n_inputs, n_hidden, n_classes)\n",
        "\n",
        "batch_size = 4096\n",
        "n_batches = (len(train_X) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "lr = 0.8\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches}\")\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x = train_X[start_idx:end_idx]\n",
        "    batch_y = train_Y[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    print(f\"  {loss.item()}\")\n",
        "    with torch.no_grad():\n",
        "      for param in model.params():\n",
        "        param.sub_(param.grad * lr)\n",
        "        param.grad.zero_()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13\n",
            "  2.3169772624969482\n",
            "Training batch 2 of 13\n",
            "  2.194561243057251\n",
            "Training batch 3 of 13\n",
            "  2.040031909942627\n",
            "Training batch 4 of 13\n",
            "  1.862878680229187\n",
            "Training batch 5 of 13\n",
            "  1.6215133666992188\n",
            "Training batch 6 of 13\n",
            "  1.3944119215011597\n",
            "Training batch 7 of 13\n",
            "  1.3434137105941772\n",
            "Training batch 8 of 13\n",
            "  1.7931064367294312\n",
            "Training batch 9 of 13\n",
            "  1.5168453454971313\n",
            "Training batch 10 of 13\n",
            "  1.2937639951705933\n",
            "Training batch 11 of 13\n",
            "  1.1940127611160278\n",
            "Training batch 12 of 13\n",
            "  1.2923635244369507\n",
            "Training batch 13 of 13\n",
            "  1.4793000221252441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fRHDqTyZU_96",
        "colab_type": "code",
        "outputId": "615285a5-dd53-4062-9521-cbcd954a7e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# torch registration\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, n_hidden, n_out):\n",
        "    super(Model, self).__init__()\n",
        "    lin1 = nn.Linear(n_in, n_hidden)\n",
        "    relu = nn.ReLU()\n",
        "    lin2 = nn.Linear(n_hidden, n_out)\n",
        "    layers = [lin1, relu, lin2]\n",
        "    for idx, layer in enumerate(layers):\n",
        "      self.add_module(f\"{idx}\", layer)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    result = x\n",
        "    for layer in self.children():\n",
        "      result = layer(result)\n",
        "    \n",
        "    return result\n",
        "  \n",
        "  def params(self):\n",
        "    for layer in self.children():\n",
        "      for param in layer.parameters():\n",
        "        yield param;\n",
        "\n",
        "model = Model(n_inputs, n_hidden, n_classes)\n",
        "model(train_X);\n",
        "model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "x5kWZCeKWBrZ",
        "colab_type": "code",
        "outputId": "a717bbe3-850d-4d63-b74f-2b2c16fc3989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# the above is very much like nn.Sequential\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "7s832HmWUieL",
        "colab_type": "code",
        "outputId": "899a85ac-6a13-447e-afe0-6e22008695ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "\n",
        "batch_size = 4096\n",
        "n_batches = (len(train_X) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "lr = 0.8\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x = train_X[start_idx:end_idx]\n",
        "    batch_y = train_Y[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches} --> {loss.item():.2f}\")\n",
        "    with torch.no_grad():\n",
        "      for param in model.parameters():\n",
        "        param.sub_(param.grad * lr)\n",
        "        param.grad.zero_()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13 --> 2.33\n",
            "Training batch 2 of 13 --> 2.20\n",
            "Training batch 3 of 13 --> 2.06\n",
            "Training batch 4 of 13 --> 1.89\n",
            "Training batch 5 of 13 --> 1.65\n",
            "Training batch 6 of 13 --> 1.40\n",
            "Training batch 7 of 13 --> 1.25\n",
            "Training batch 8 of 13 --> 1.51\n",
            "Training batch 9 of 13 --> 1.92\n",
            "Training batch 10 of 13 --> 1.98\n",
            "Training batch 11 of 13 --> 1.81\n",
            "Training batch 12 of 13 --> 1.30\n",
            "Training batch 13 of 13 --> 1.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iaS3udaVW7js",
        "colab_type": "code",
        "outputId": "f81f2075-9ba2-4288-9b4e-f5c26ad113c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# using optim\n",
        "from torch import optim\n",
        "\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "\n",
        "lr = 0.8\n",
        "opt = optim.SGD(params = model.parameters(), lr = lr)\n",
        "batch_size = 4096\n",
        "n_batches = (len(train_X) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x = train_X[start_idx:end_idx]\n",
        "    batch_y = train_Y[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches} --> {loss.item():.2f}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13 --> 2.30\n",
            "Training batch 2 of 13 --> 2.17\n",
            "Training batch 3 of 13 --> 2.00\n",
            "Training batch 4 of 13 --> 1.81\n",
            "Training batch 5 of 13 --> 1.57\n",
            "Training batch 6 of 13 --> 1.38\n",
            "Training batch 7 of 13 --> 1.57\n",
            "Training batch 8 of 13 --> 1.69\n",
            "Training batch 9 of 13 --> 1.23\n",
            "Training batch 10 of 13 --> 0.94\n",
            "Training batch 11 of 13 --> 0.86\n",
            "Training batch 12 of 13 --> 0.96\n",
            "Training batch 13 of 13 --> 1.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KV4u-HG2Tf3H",
        "colab_type": "code",
        "outputId": "18b40063-e587-4da4-abdf-739e3781a112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "[param.shape for param in model.parameters()]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([100, 784]),\n",
              " torch.Size([100]),\n",
              " torch.Size([10, 100]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "0r9l3naiSbxL",
        "colab_type": "code",
        "outputId": "1618b7f7-f275-4550-8096-458a762ca1d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "  def __init__(self, x, target):\n",
        "    self.x = x\n",
        "    self.target = target\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.target[idx]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.target)\n",
        "\n",
        "dataset = Dataset(train_X, train_Y)\n",
        "x,y = dataset[1:2]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 784]), torch.Size([1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "yWnJK4SCTBRT",
        "colab_type": "code",
        "outputId": "e121b7ec-5fa5-4106-bb9f-1909700936ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(train_X, train_Y)\n",
        "\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "\n",
        "lr = 0.8\n",
        "opt = optim.SGD(params = model.parameters(), lr = lr)\n",
        "batch_size = 4096\n",
        "n_batches = (len(dataset) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for batch_idx in range(n_batches):\n",
        "    start_idx = batch_size * batch_idx\n",
        "    end_idx = batch_size * (batch_idx + 1)\n",
        "    batch_x, batch_y = dataset[start_idx:end_idx]\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches} --> {loss.item():.2f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1 of 13 --> 2.30\n",
            "Training batch 2 of 13 --> 2.20\n",
            "Training batch 3 of 13 --> 2.05\n",
            "Training batch 4 of 13 --> 1.88\n",
            "Training batch 5 of 13 --> 1.64\n",
            "Training batch 6 of 13 --> 1.39\n",
            "Training batch 7 of 13 --> 1.30\n",
            "Training batch 8 of 13 --> 1.82\n",
            "Training batch 9 of 13 --> 1.71\n",
            "Training batch 10 of 13 --> 1.34\n",
            "Training batch 11 of 13 --> 1.10\n",
            "Training batch 12 of 13 --> 1.11\n",
            "Training batch 13 of 13 --> 1.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z8vuVLUlUSOf",
        "colab_type": "code",
        "outputId": "f91fdbfa-7c39-4b59-b28b-45d6a6355e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class Dataloader():\n",
        "  def __init__(self, dataset, batch_size=100):\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for batch_idx in range(n_batches):\n",
        "      start_idx = batch_size * batch_idx\n",
        "      end_idx = batch_size * (batch_idx + 1)\n",
        "      batch_x, batch_y = dataset[start_idx:end_idx]\n",
        "      yield (batch_x, batch_y)\n",
        "      \n",
        "dataloader = Dataloader(dataset)\n",
        "batch_x, batch_y = next(iter(dataloader))\n",
        "batch_x.shape, batch_y.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4096, 784]), torch.Size([4096]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "ES3-NuVOa-HF",
        "colab_type": "code",
        "outputId": "e5596c6c-dd3c-4f20-ed2c-ec49fe9c2eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from torch import tensor\n",
        "tensor([[0, 1, 1],[1,0,0]]).argmax(dim=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "CH2UPPdGbArg",
        "colab_type": "code",
        "outputId": "f6d44b38-6688-473c-be10-992d9c949169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tensor([[0, 1, 1.5],[13,0,0]])[range(2),tensor([2, 0])]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.5000, 13.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "5iijTcewZ7ua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(actual, expected):\n",
        "  idx = actual.argmax(dim=1)\n",
        "  return (idx == expected).float().mean()\n",
        "\n",
        "from torch import tensor\n",
        "test_eq(accuracy(tensor([[0, 1, 0.1]]), tensor([1])), 1)\n",
        "test_eq(accuracy(tensor([[0, 0.3, 0.7]]), tensor([2])), 1)\n",
        "test_eq(accuracy(tensor([[0, 0.3, 0]]), tensor([2])), 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHrXuzMpa1IJ",
        "colab_type": "code",
        "outputId": "7d6bbf68-e25c-47c6-fb2c-d44dbeb52009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tensor([[0, 1, 1],[1,0,0]]).argmax(dim=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "V41Ee-qcTPW9",
        "colab_type": "code",
        "outputId": "c6809864-cd04-4ad1-884c-626ed3fddccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(train_X, train_Y)\n",
        "dataloader = Dataloader(dataset)\n",
        "\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "\n",
        "lr = 0.5\n",
        "opt = optim.SGD(params = model.parameters(), lr = lr)\n",
        "batch_size = 4096\n",
        "n_batches = (len(dataset) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for (batch_x, batch_y) in dataloader:\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    print(f\"Training batch {batch_idx+1} of {n_batches} --> {loss.item():.3f}\")\n",
        "    \n",
        "  t_acc = accuracy(model(train_X), train_Y)\n",
        "  v_acc = accuracy(model(valid_X), valid_Y)\n",
        "  print(f\"Accuracy train: {t_acc:.3f}, validation: {v_acc:.3f}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 13 of 13 --> 2.314\n",
            "Training batch 13 of 13 --> 2.229\n",
            "Training batch 13 of 13 --> 2.134\n",
            "Training batch 13 of 13 --> 2.038\n",
            "Training batch 13 of 13 --> 1.910\n",
            "Training batch 13 of 13 --> 1.754\n",
            "Training batch 13 of 13 --> 1.593\n",
            "Training batch 13 of 13 --> 1.494\n",
            "Training batch 13 of 13 --> 1.301\n",
            "Training batch 13 of 13 --> 1.177\n",
            "Training batch 13 of 13 --> 1.104\n",
            "Training batch 13 of 13 --> 0.985\n",
            "Training batch 13 of 13 --> 1.012\n",
            "Accuracy train: 0.655, validation: 0.670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZnr8rJoUIKU",
        "colab_type": "code",
        "outputId": "779cf28b-a43b-496c-f48e-c8652e822eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class Sampler():\n",
        "  def __init__(self, dataset, batch_size = 64, shuffle=False):\n",
        "    self.dataset = dataset\n",
        "    self.len = len(dataset)\n",
        "    self.shuffle = shuffle\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "  def __iter__(self):\n",
        "    self.idxs = torch.randperm(self.len) if self.shuffle else torch.arange(self.len)\n",
        "    for i in range(0, self.len, self.batch_size): yield self.idxs[i:i+self.batch_size]\n",
        "\n",
        "s = Sampler(Dataset(train_X[:5], train_Y[:5]), 3, False)\n",
        "[o for o in s]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "RVw2BjJsdKMs",
        "colab_type": "code",
        "outputId": "6dcf4628-855c-40fa-f95f-ad3f176585bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "s = Sampler(Dataset(train_X[:5], train_Y[:5]), 3, False)\n",
        "[o for o in s]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "RJHWRX5gd97M",
        "colab_type": "code",
        "outputId": "ed2d844c-f52d-4de9-a403-f233ee197ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "s = Sampler(Dataset(train_X[:5], train_Y[:5]), 3, True)\n",
        "[o for o in s]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([3, 0, 2]), tensor([1, 4])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "rua2IBe9d_az",
        "colab_type": "code",
        "outputId": "0323f058-e3d2-4e34-9f3c-df633f8a45b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "s = Sampler(Dataset(train_X[:5], train_Y[:5]), 3, False)\n",
        "[o for o in s]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "HUAm0JP7eEyl",
        "colab_type": "code",
        "outputId": "94c645ae-13ad-4043-96ff-313c5465451f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class Dataloader():\n",
        "  def __init__(self, dataset, sampler, batch_size=100):\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.sampler = sampler\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for batch_idx in self.sampler:\n",
        "      batch_x, batch_y = self.dataset[batch_idx]\n",
        "      yield (batch_x, batch_y)\n",
        "\n",
        "dataset = Dataset(train_X, train_Y)\n",
        "sampler = Sampler(dataset, shuffle = True)\n",
        "dataloader = Dataloader(dataset, sampler)\n",
        "\n",
        "x,y = next(iter(dataloader))\n",
        "x.shape, y.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 784]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "dyJmAImAe30D",
        "colab_type": "code",
        "outputId": "c8b5d2b3-8baf-4d7e-802c-9a84370ac1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(train_X, train_Y)\n",
        "sampler = Sampler(dataset, shuffle = True, batch_size=batch_size)\n",
        "dataloader = Dataloader(dataset, sampler, batch_size=batch_size)\n",
        "\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "\n",
        "lr = 0.5\n",
        "opt = optim.SGD(params = model.parameters(), lr = lr)\n",
        "n_batches = (len(dataset) - 1) // batch_size + 1\n",
        "n_epochs = 1\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for idx, (batch_x, batch_y) in enumerate(dataloader):\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    print(f\"Training batch {idx+1}. Length {len(batch_x)} --> {loss.item():.3f}\")\n",
        "    \n",
        "  t_acc = accuracy(model(train_X), train_Y)\n",
        "  v_acc = accuracy(model(valid_X), valid_Y)\n",
        "  print(f\"Accuracy train: {t_acc:.3f}, validation: {v_acc:.3f}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batch 1. Length 4096 --> 2.315\n",
            "Training batch 2. Length 4096 --> 2.242\n",
            "Training batch 3. Length 4096 --> 2.163\n",
            "Training batch 4. Length 4096 --> 2.074\n",
            "Training batch 5. Length 4096 --> 1.962\n",
            "Training batch 6. Length 4096 --> 1.826\n",
            "Training batch 7. Length 4096 --> 1.667\n",
            "Training batch 8. Length 4096 --> 1.530\n",
            "Training batch 9. Length 4096 --> 1.375\n",
            "Training batch 10. Length 4096 --> 1.242\n",
            "Training batch 11. Length 4096 --> 1.123\n",
            "Training batch 12. Length 4096 --> 1.067\n",
            "Training batch 13. Length 848 --> 1.076\n",
            "Accuracy train: 0.615, validation: 0.628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gXBsXXqHe8ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f8c08bf8-3c73-4129-f97b-c9da1e67625b"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "dataset = Dataset(train_X, train_Y)\n",
        "sampler = Sampler(dataset, shuffle = True, batch_size=batch_size)\n",
        "dataloader = Dataloader(dataset, sampler, batch_size=batch_size)\n",
        "\n",
        "v_dataset = Dataset(valid_X, valid_Y)\n",
        "v_sampler = Sampler(v_dataset, shuffle = False, batch_size=batch_size)\n",
        "v_dataloader = Dataloader(v_dataset, v_sampler, batch_size=batch_size)\n",
        "\n",
        "n_hidden = 50\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(n_inputs, n_hidden),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_hidden, n_classes)\n",
        ")\n",
        "\n",
        "lr = 0.5\n",
        "opt = optim.SGD(params = model.parameters(), lr = lr)\n",
        "n_batches = (len(dataset) - 1) // batch_size + 1\n",
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  model.train()\n",
        "  for (batch_x, batch_y) in dataloader:\n",
        "    preds = model(batch_x)\n",
        "    loss = F.cross_entropy(preds, batch_y)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  \n",
        "  model.eval()\n",
        "  accuracy_exp_avg = 0\n",
        "  loss_exp_avg = 0\n",
        "  for idx, (v_batch_x, v_batch_y) in enumerate(v_dataloader):\n",
        "    with torch.no_grad():\n",
        "      v_preds = model(v_batch_x)\n",
        "      loss = F.cross_entropy(v_preds, v_batch_y)\n",
        "      avg_coeff = 0.5\n",
        "      accuracy_exp_avg = accuracy_exp_avg * avg_coeff + accuracy(v_preds, v_batch_y) * (1 - avg_coeff)\n",
        "      loss_exp_avg     = loss_exp_avg * avg_coeff + loss * (1 - avg_coeff)\n",
        " \n",
        "  print(f\"Epoch {epoch}/{n_epochs}. Validation metrics. Loss: {loss_exp_avg:.3f}, accuracy: {accuracy_exp_avg:.3f}\")\n",
        "  \n",
        "model.eval()\n",
        "\n",
        "t_preds = model(train_X)\n",
        "v_preds = model(valid_X)\n",
        "t_acc = accuracy(t_preds, train_Y)\n",
        "v_acc = accuracy(v_preds, valid_Y)\n",
        "t_loss = F.cross_entropy(t_preds, train_Y)\n",
        "v_loss = F.cross_entropy(v_preds, valid_Y)\n",
        "print(f\"Accuracy train: {t_acc:.3f} (loss: {t_loss:.3f}), validation: {v_acc:.3f} (loss: {v_loss:.3f})\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/5. Validation metrics. Loss: 0.166, accuracy: 0.964\n",
            "Epoch 1/5. Validation metrics. Loss: 0.302, accuracy: 0.928\n",
            "Epoch 2/5. Validation metrics. Loss: 0.092, accuracy: 0.986\n",
            "Epoch 3/5. Validation metrics. Loss: 0.109, accuracy: 0.986\n",
            "Epoch 4/5. Validation metrics. Loss: 0.094, accuracy: 0.986\n",
            "Accuracy train: 0.960 (loss: 0.131), validation: 0.955 (loss: 0.168)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HGh2IiH5s356",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f68a9c7c-d197-47b1-ed23-b81eadda90d9"
      },
      "cell_type": "code",
      "source": [
        "len(v_dataset)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "BS66TFyCzivM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get data\n",
        "# lin-relu-lin\n",
        "# log_softmax \n",
        "# nll\n",
        "# logsumexp in log_softmax\n",
        "# basica training loop, epochs, batches, manual changes to weights\n",
        "# iterate over params\n",
        "# registering the modules\n",
        "# nn.Sequential\n",
        "# optimizer\n",
        "# grad accumulation cleanup\n",
        "# dataset & dataloader\n",
        "# random sampling\n",
        "# validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCOWph8nTLX1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.utils.data.TensorDataset??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xcil9qPWTbAM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}